{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "poets_scrape.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Z1_dvqA2U6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rwCVUJbA497"
      },
      "source": [
        "base_path = '/content/drive/My Drive/DM Challenge'\n",
        "save_path = base_path + '/poets_with_imgs.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUMYuVbMPq3i"
      },
      "source": [
        "import requests\n",
        "source = 'http://famouspoetsandpoems.com'\n",
        "page = requests.get(source+'/poets.html')\n",
        "page"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjeT0IACRA_K"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "main_soup = BeautifulSoup(page.content, 'html.parser')\n",
        "poets = main_soup.find('table', cellspacing='0').find('table').find_all('td', valign='top')\n",
        "print (poets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WtXKf059Bri"
      },
      "source": [
        "!pip install deep-translator\n",
        "from deep_translator import GoogleTranslator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QwszyGBQm7i0",
        "outputId": "0e0e6e43-8363-4510-e76e-6d00e3f13681"
      },
      "source": [
        "'''fields:\n",
        "1. name\n",
        "2. birth_year\n",
        "3. death_year\n",
        "4. bio\n",
        "5. poem\n",
        "6. quote\n",
        "7. category (school)\n",
        "8. similar poets\n",
        "9. image\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fields:\\n1. name\\n2. birth_year\\n3. death_year\\n4. bio\\n5. poem\\n6. quote\\n7. category (school)\\n8. similar poets\\n9. image\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GFAtp2Qjv3u"
      },
      "source": [
        "from bs4 import NavigableString, Tag\n",
        "import pandas as pd\n",
        "import re\n",
        "poets_df = pd.DataFrame(columns=['name', 'birth_year', 'death_year', 'categories', 'bio', 'poem', 'quote', 'similar_poets', 'image'])\n",
        "\n",
        "for i in range(1000):\n",
        "  try:\n",
        "    td = poets[i]\n",
        "\n",
        "    url = td.find('a')['href']\n",
        "    text = td.text.split('(')\n",
        "\n",
        "    name = text[0].strip()\n",
        "    name_sin = GoogleTranslator(source='en', target='si').translate(name)\n",
        "    birth_year = text[2].split('-')[0].strip()\n",
        "    if not birth_year.isnumeric():\n",
        "      birth_year = GoogleTranslator(source='en', target='si').translate(birth_year)\n",
        "    death_year = text[2].split('-')[1].strip(')').strip()\n",
        "    if not death_year.isnumeric():\n",
        "      death_year = GoogleTranslator(source='en', target='si').translate(death_year)\n",
        "    \n",
        "    bio_page = requests.get('https://poets.org/poet/'+'-'.join(name.split()))\n",
        "    bio_soup = BeautifulSoup(bio_page.content, 'html.parser')\n",
        "    bio = bio_soup.find('div', class_='poet__body-content').text\n",
        "    bio_sin = GoogleTranslator(source='en', target='si').translate(bio)\n",
        "\n",
        "    try:\n",
        "      img_page = requests.get(source+url+'/photo')\n",
        "      img_soup = BeautifulSoup(img_page.content, 'html.parser')\n",
        "      img = source+img_soup.find('img', alt=name)['src']\n",
        "    except:\n",
        "      img = 'http://famouspoetsandpoems.com/images/_no_photo.gif'\n",
        "\n",
        "    categories = [c.text.strip() for c in bio_soup.find_all('div', class_='school')]\n",
        "    categories_sin = ', '.join([GoogleTranslator(source='en', target='si').translate(c) for c in categories])\n",
        "    \n",
        "    similar_poets = [p.text.strip() for p in bio_soup.find_all('div', class_='poet__sidebar-related-poets-poet')]\n",
        "    similar_poets_sin = ', '.join([GoogleTranslator(source='en', target='si').translate(p) for p in similar_poets])\n",
        "\n",
        "    poems_page = requests.get(source+url+'/poems')\n",
        "    poems_soup = BeautifulSoup(poems_page.content, 'html.parser')\n",
        "    poem_url = poems_soup.find_all('table', width='436')[1].find_all('a')[0]['href']\n",
        "    poem_page = requests.get(source+poem_url)\n",
        "    poem_soup = BeautifulSoup(poem_page.content, 'html.parser')\n",
        "    poem = (str(poem_soup.find('div', style='padding-left:14px;padding-top:20px;font-family:Arial;font-size:13px;')).strip('<div style=\"padding-left:14px;padding-top:20px;font-family:Arial;font-size:13px;\">').strip('</div>').strip().split('<br/>'))\n",
        "    poem_sin = '\\n'.join([GoogleTranslator(source='en', target='si').translate(i) for i in poem if i!=''])\n",
        "    \n",
        "    quotes_page = requests.get(source+url+'/quotes')\n",
        "    quotes_soup = BeautifulSoup(quotes_page.content, 'html.parser')\n",
        "    quotes = quotes_soup.find_all('div', style='padding-right:15px;padding-left:16px;padding-bottom:20px;')\n",
        "    if len(quotes)>0:\n",
        "      quote = quotes[0].text\n",
        "      quote_sin = GoogleTranslator(source='en', target='si').translate(quote)\n",
        "    else:\n",
        "      quote = None\n",
        "      quote_sin = None\n",
        "    \n",
        "    if re.search('[a-zA-Z]', name_sin):\n",
        "      print (name_sin)\n",
        "      continue\n",
        "    \n",
        "    poets_df.loc[i] = [name_sin, birth_year, death_year, categories_sin, bio_sin, poem_sin, quote_sin, similar_poets_sin, img]\n",
        "    print (i, name_sin)\n",
        "\n",
        "  except:\n",
        "    continue\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqYn-SPFltlh"
      },
      "source": [
        "poets_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJp9w-dpNz67"
      },
      "source": [
        "poets_df.to_csv(save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}